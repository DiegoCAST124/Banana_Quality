# -*- coding: utf-8 -*-
"""ACD_Classification-Banana.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1raXrgILujMEm5EneqeneMW1-YYou6BGw

#Regresi√≥n Log√≠stica con ScikitLearn para predecir la calidad de pl√°tanos

Aprendizaje Autom√°tico

Ene-Jun 2024

#Introducci√≥n

En la industria agr√≠cola, la clasificaci√≥n de los productos es fundamental para asegurar que los consumidores reciban alimentos que cumplan con est√°ndares de calidad. En el caso de los pl√°tanos la determinaci√≥n de su calidad no solo impacta en la satisfacci√≥n del consumidor, sino tambi√©n a la gesti√≥n de precios, almacenamiento y log√≠stica de distribuci√≥n. Tradicionalmente la evaluaci√≥n de la calidad se ha realizado manualmente, lo que implica un proceso subjetivo y laborioso.

Dada la creciente demanda de eficiencia y objetividad se ha identificado la necesidad de desarrollar modelos autom√°ticos que puedan realizar esta tarea de manera confiable y consistente. Los modelos de regresi√≥n alimentados por datos hist√≥ricos y variables relevantes surgen como una soluci√≥n prometedora para automatizar la clasificaci√≥n de la calidad de los pl√°tanos.

El objetivo de este proyecto es desarrollar y validar un modelo de regresi√≥n que pueda predecir la calidad de los pl√°tanos bas√°ndose en un conjunto de caracteristicas cuantificables tales como; el tama√±o, peso, dulzor, suavidad, √©poca de cosecha, madurez, y acidez. Para ello utilizaremos un dataset de Kaggle llamado üçå | Banana Quality (https://www.kaggle.com/datasets/l3llff/banana).

La capacidad de predecir de manera precisa la calidad de los pl√°tanos no solo optimizar√° los procesos internos de los productores y distribuidores, sino que mejorar√° la experiencia de compra de los consumidores.

#Importaci√≥n de bibliotecas necesarias y preprocesamiento de datos

Importamos las bibliotecas y subibliotecas necesarios para el procedimiento.

Pandas nos permite leer y escribir en ficheros en formato CSV; as√≠ como accceder, reordenar, dividir y combinar conjuntos de datos.

Matplotlib nos ayuda a crear gr√°ficas.

Seaborn es una herramienta de Data Visualization nos permite transformar los datos brutos en diagramas.

Scikit-learn es una biblioteca para machine learning de software libre para el lenguaje de Python, incluye varios algoritmos de clasificaci√≥n, regresi√≥n y an√°lisis de grupos.
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.preprocessing import MinMaxScaler
from sklearn.pipeline import Pipeline
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.svm import SVC
from sklearn.metrics import accuracy_score, roc_auc_score, roc_curve
from sklearn.feature_selection import SelectKBest
from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score

#Importamos el csv y lo leemos con pandas
data = pd.read_csv("banana_quality.csv")
#"Dropeamos" o mejor dicho eliminamos los datos vacios
data.dropna(inplace=True)
data

"""Verificamos si existen datos nulos en nuestro dataset.

La expresi√≥n df.isnull() devuelve un DataFrame booleano que tiene el mismo tama√±o que df, donde cada valor nulo es True y en caso contrario False.

.sum() se aplica al dataframe booleano, suma los valores en cada columna, la suma de cada columna dar√° el recuento de valores nulos en cada columna (1 True, 0 False).

El segundo .sum() se aplica al primer .sum().
"""

data.isnull().sum().sum()

#Visualizamos la informacion de los datos
data.info()

"""
C√≥mo la variable de salida es de tipo objeto y no de tipo num√©rico debemos convertirlo, para ello usaremos el siguiente comando."""

data = data.replace({"Bad": 0, "Good": 1})
data

#Histogramas
data.hist(bins=15, figsize=(15,6), layout=(2,4))
plt.show()

#Mapa de calor de la correlacion
sns.heatmap(data.corr(), annot=True, cmap='coolwarm')
plt.title('Mapa de calor de correlacion')
correlation = data.corr()
print(correlation['Quality'])
plt.show()

#Describimos las caracteristicas estadisticas de las variables
data.describe()

"""Separamos el conjunto de datos en caracteristicas (X) y las variables de salida/objetivo (y)"""

X = data.drop("Quality", axis=1)
y = data["Quality"]

X

y

"""#Prueba de diferentes modelos de machine learning

Probaremos diferentes modelos de machine learning para conocer el m√°s apto para este conjunto de datos.

"""

#Dividimos los datos en una proporcion de 80/20
X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8, random_state=42)

"""##Regresi√≥n log√≠stica

La regresi√≥n log√≠stica es un algoritmo de clasificaci√≥n que se utiliza para predecir la probabilidad de una variable dependiente categ√≥rica. En la regresi√≥n log√≠stica, la variable dependiente es una variable binaria que contiene datos codificados como 1 ‚Äì 0, s√≠ ‚Äì no, abierto ‚Äì cerrado, etc.

El resultado o variable objetivo es de naturaleza dicot√≥mica. Dicot√≥mica significa que solo hay dos clases posibles. Por ejemplo, se puede utilizar para problemas de detecci√≥n de c√°ncer o calcular la probabilidad de que ocurra un evento.

Es uno de los algoritmos de Machine Learning m√°s simples y m√°s utilizados para la clasificaci√≥n de dos clases. Es f√°cil de implementar y se puede usar como l√≠nea de base para cualquier problema de clasificaci√≥n binaria.

Se utiliza para estimar la probabilidad de una respuesta binaria basada en una o m√°s variables predictoras o independientes. Permite decir que la presencia de un factor de riesgo aumenta la probabilidad de un resultado dado un porcentaje espec√≠fico.

Valores por defecto de la Regresi√≥n Log√≠stica:


1.   penalty='l2'
2.   dual=False
3.   tol=0.0001
4.   C=1.0
5.   fit_intercept=True
6.   intercept_scaling=1
7.   class_weight=None
8.   random_state=None
9.   solver='lbfgs'
10.   max_iter=100
11.   multi_class='deprecated'
12.   verbose=0
13.   warm_start=False
14.   n_jobs=None
15.    l1_ratio=None
"""

# Regresi√≥n Log√≠stica con par√°metros por defecto
lr_default = LogisticRegression()
lr_default.fit(X_train, y_train)

# Predicciones
y_pred_lr_default = lr_default.predict(X_test)

y_pred_probs = lr_default.predict_proba(X_test)[:,1]
score = roc_auc_score(y_test, y_pred_lr_default)
fpr, tpr, thresholds = roc_curve(y_test, y_pred_lr_default)

print(f"Precision en el conjunto de entrenamiento: {lr_default.score(X_train, y_train):.9f}")
print(f"Precision en el conjunto de prueba: {lr_default.score(X_test, y_test):.9f}")

print(f"ROC-AUC score: {score}")
plt.figure()
plt.title("Logistic Regression Default Curve ROC ")
plt.plot(fpr,tpr,color='red', label=f'AUC ROC= {score:.5f})')
plt.plot([0,1],[0,1],linestyle='--',color='gray')
plt.xlabel("False Positive Rate")
plt.ylabel("True Positive Rate")
plt.legend(loc='lower right')
plt.show()

#METRICAS CON LOS DATOS POR DEFAULT

#Calculamos las metricas
accuracy = accuracy_score(y_test, y_pred_lr_default)
precision = precision_score(y_test, y_pred_lr_default)
recall = recall_score(y_test, y_pred_lr_default)
f1 = f1_score(y_test, y_pred_lr_default)

#Mostramos las metricas
print(f"Accuracy: {accuracy:.3f}")
print(f"Precision {precision:.3f}")
print(f"recall: {recall:.3f}")
print(f"F1 Score: {f1:.3f}")

#Calculamos y mostramos la matriz de confusion
conf_matrix = confusion_matrix(y_test, y_pred_lr_default)

plt.figure(figsize=(8, 6))
sns.heatmap(conf_matrix, annot=True, fmt="d", cmap="Blues")
plt.xlabel("Negative Labels")
plt.ylabel("True Labels")
plt.title("Logistic Regression Default Confusion Matrix")
plt.show()

#Creamos y configuramos un pipeline con seleccion de caracteristicas,
#escalado y clasificacion
selector = SelectKBest()
scaler = MinMaxScaler()
clf = LogisticRegression(max_iter = 1000)

lr_pl = Pipeline([('selector',selector),
               ('escalador',scaler),
               ('clasificador',clf)])

#Definimos el diccionario param_grid que contiene las combinaciones de param√©tros
#que se probar√°n durante la b√∫squeda de hiperparam√©tros.
param_grid = {
    "selector__k":[2,3,4,5], #N√∫mero de caracteristicas seleccionadas
    "clasificador__C":[0.1,0.5,1,2], #Valores de regularizaci√≥n
    "clasificador__solver":['lbfgs','newton-cg','sag', 'saga', 'newton-cholesky', 'liblinear'], #Solucionadores
    #"clasificador__penalty":[None,'l2','l1'] #Penalizaciones
}
#Creamos el diccionario solvers_penalties que contiene los solucionadores disponibles
#y las penalizaciones compatibles con cada solucionador. Esto para generar combinacionrs
#v√°lidas de solucionadores y penalizaciones.
solvers_penalties = {
    'lbfgs' : ['none', 'l2'],
    'newton-cg' : ['none', 'l2'],
    'sag' : ['none', 'l2'],
    'saga' : ['none', 'l2', 'l1', 'elasticnet'],
    'newton-cholesky' : ['none', 'l2'],
    'liblinear' : ['l1', 'l2']
}

#Generamos combinaciones validas de solver y penalizacion
param_grid['clasificador__solver'] = []
param_grid['clasificador__penalty'] = []
for solver, penalties in solvers_penalties.items():
  for penalty in penalties:
    param_grid['clasificador__solver'].append(solver)
    param_grid['clasificador__penalty'].append(penalty)

#Realizamos la busqueda en cuadricula con validacion cruzada
search = GridSearchCV(lr_pl, param_grid, n_jobs=-1, cv=5)
search.fit(X_train, y_train)

#Mejores parametros y score obtenido
print("Mejores parametros para LR: ", search.best_params_)
print("Mejor accuracy para LR obtenida en validacion cruzada: ", search.best_score_)

#Evaluamos el modelo con los mejores parametros encontrados
best_model = search.best_estimator_
print(f"Precision en el conjunto de entrenamiento: {best_model.score(X_train, y_train):.9f}")
print(f"Precision en el conjunto de prueba: {best_model.score(X_test, y_test):.9f}")

#Calculamos y mostramos la curva ROC-AUC
y_pred_probs_lr = best_model.predict_proba(X_test)[:,1]
score = roc_auc_score(y_test, y_pred_probs_lr)
fpr, tpr, thresholds = roc_curve(y_test, y_pred_probs_lr)

print(f"ROC-AUC score: {score}")
plt.figure()
plt.title("Logistic Regression Best Curve ROC")
plt.plot(fpr,tpr,color='red', label=f'AUC ROC= {score:.5f})')
plt.plot([0,1],[0,1],linestyle='--',color='gray')
plt.xlabel("False Positive Rate")
plt.ylabel("True Positive Rate")
plt.legend(loc='lower right')
plt.show()

#METRICAS

#Predecimos los valores de y para el conjunto de prueba
y_pred_lr = best_model.predict(X_test)

#Calculamos las metricas
accuracy = accuracy_score(y_test, y_pred_lr)
precision = precision_score(y_test, y_pred_lr)
recall = recall_score(y_test, y_pred_lr)
f1 = f1_score(y_test, y_pred_lr)

#Mostramos las metricas
print(f"Accuracy: {accuracy:.3f}")
print(f"Presicion {precision:.3f}")
print(f"recall: {recall:.3f}")
print(f"F1 Score: {f1:.3f}")

#Calculamos y mostramos la matriz de confusion
conf_matrix = confusion_matrix(y_test, y_pred_lr)
plt.figure(figsize=(8, 6))
sns.heatmap(conf_matrix, annot=True, fmt="d", cmap="Blues")
plt.xlabel("Negative Labels")
plt.ylabel("True Labels")
plt.title("Logistic Regression Best Confusion Matrix")
plt.show()

"""##M√°quinas de vectores de soporte SVM

Las m√°quinas de vectores de soporte o m√°quinas de vector soporte (del ingl√©s support-vector machine SVM) son un conjunto de algoritmos de aprendizaje supervisado desarrollados por Vladimir Vapnik y su equipo en los laboratorios AT&T Bell.
Est√°n propiamente relcionados con problemas de clasificaci√≥n y regresi√≥n. Dado un conjunto de muestras podemos etiquetar las clases y formar una SVM para construir un modelo que prediga la clase de una nueva muestra. Una SVM es un modelo que representa a los puntos de muestra en el espacio, separando las clases a 2 espacios lo m√°s amplios posibles mediante un hiperplano de separaci√≥n definido como el vector entre los 2 puntos, de las 2 clases, m√°s cercanos al que se llama vector soporte. Cuando las nuevas muestras se ponen en correspondencia con dicho modelo, en funci√≥n de los espacios a los que pertenezcan, pueden ser clasificados a una o la otra clase.

Como en la mayor√≠a de los m√©todos de clasificaci√≥n supervisada, los datos de entrada son vistos como un vector p-dimensional.

En la literatura de las SVM, se llama atributo a la variable predictora y caracter√≠stica a un atributo transformado que es usado para definir el hiperplano. La elecci√≥n de la representaci√≥n m√°s adecuada del universo estudiado se realiza mediante un proceso denominado selecci√≥n de caracter√≠sticas. Al vector formado por los puntos m√°s cercanos al hiperplano se le llama vector de soporte.

Los modelos basados en SVM est√°n estrechamente relacionados con las redes neuronales. Usando una funci√≥n kernel, resultan un m√©todo de formaci√≥n alternativo para clasificadores polinomiales, funciones de base radial y perceptr√≥n multicapa.

Parametros por default:



1.   C=1.0
2.   kernel='rbf'
3.   degree=3
4.   gamma='scale'
5.   coef0=0.0
6.   shrinking=True
7.   probability=False
8.   tol=0.001
9.   cache_size=200
10.   class_weight=None
11.   verbose=False
12.   max_iter=-1
13.   decision_function_shape='ovr'
14.   break_ties=False
15.   random_state=None
"""

# SVM con par√°metros por defecto
svm_default = SVC(probability=True)
svm_default.fit(X_train, y_train)

print(f"Precision en el conjunto de entrenamiento: {svm_default.score(X_train, y_train):.9f}")
print(f"Precision en el conjunto de prueba: {svm_default.score(X_test, y_test):.9f}")

# Predicciones
y_pred_svm_default = svm_default.predict(X_test)

y_pred_probs = svm_default.predict_proba(X_test)[:,1]
score = roc_auc_score(y_test, y_pred_probs)
fpr, tpr, thresholds = roc_curve(y_test, y_pred_probs)

print(f"ROC-AUC score: {score}")
plt.figure()
plt.title("SVM Default Curve ROC")
plt.plot(fpr,tpr,color='red', label=f'AUC ROC= {score:.5f})')
plt.plot([0,1],[0,1],linestyle='--',color='gray')
plt.xlabel("False Positive Rate")
plt.ylabel("True Positive Rate")
plt.legend(loc='lower right')
plt.show()

#METRICAS CON LOS DATOS POR DEFAULT

#Calculamos las metricas
accuracy = accuracy_score(y_test, y_pred_svm_default)
precision = precision_score(y_test, y_pred_svm_default)
recall = recall_score(y_test, y_pred_svm_default)
f1 = f1_score(y_test, y_pred_svm_default)

#Mostramos las metricas
print(f"Accuracy: {accuracy:.3f}")
print(f"Presicion {precision:.3f}")
print(f"recall: {recall:.3f}")
print(f"F1 Score: {f1:.3f}")

#Calculamos y mostramos la matriz de confusion
conf_matrix = confusion_matrix(y_test, y_pred_svm_default)
plt.figure(figsize=(8, 6))
sns.heatmap(conf_matrix, annot=True, fmt="d", cmap="Blues")
plt.xlabel("Negative Labels")
plt.ylabel("True Labels")
plt.title("SVM Default Confusion Matrix")
plt.show()

#Configuracion del Pipeline para SVM
svm_pipeline = Pipeline([
    ('scaler', MinMaxScaler()), #Escalado de los datos para SVM
    ('svm', SVC(probability=True))
])

#Parametros a evaluar en la busqueda de cuadricula para SVM
param_grid_svm = {
    'svm__C': [0.1, 1, 10], #Valores del parametro de regularizacion C
    'svm__kernel': ['rbf', 'linear'], #Tipos de kernel a probar
    'svm__gamma': ['scale', 'auto'] #Coeficiente del kernel para 'rbf
}

#Busqueda de cuadricula con validacion cruzada
grid_search_svm = GridSearchCV(svm_pipeline, param_grid_svm, cv=5, scoring='accuracy')
grid_search_svm.fit(X_train, y_train)

#Mejores parametros y score obtenido
print("Mejores parametros para SVM: ", grid_search_svm.best_params_)
print("Mejor accuracy para SVM obtenida en validacion cruzada: ", grid_search_svm.best_score_)

best_model = grid_search_svm.best_estimator_
print(f"Precision en el conjunto de entrenamiento: {best_model.score(X_train, y_train):.9f}")
print(f"Precision en el conjunto de prueba: {best_model.score(X_test, y_test):.9f}")

#Curva ROC para SVM
svm_pred_probs = grid_search_svm.predict_proba(X_test)[:, 1]
svm_score = roc_auc_score(y_test, svm_pred_probs)
svm_fpr, svm_tpr, _ = roc_curve(y_test, svm_pred_probs)

#Grafica de la curva ROC
plt.figure()
plt.title("SVM Best Curve ROC")
plt.plot(svm_fpr,svm_tpr,color='red', label=f'AUC ROC= {score:.5f})')
plt.plot([0,1],[0,1],linestyle='--',color='gray')
plt.xlabel("False Positive Rate")
plt.ylabel("True Positive Rate")
plt.legend(loc='lower right')
plt.show()

#METRICAS

#Generamos las predicciones del modelo SVM
svm_y_pred = grid_search_svm.predict(X_test)

#Calculamos las metricas
svm_accuracy = accuracy_score(y_test, svm_y_pred)
svm_precision = precision_score(y_test, svm_y_pred)
svm_recall = recall_score(y_test, svm_y_pred)
svm_f1 = f1_score(y_test, svm_y_pred)

print(f"SVM Accuracy: {svm_accuracy: .3f}")
print(f"SVM Precision: {svm_precision: .3f}")
print(f"SVM Recall: {svm_recall: .3f}")
print(f"SVM F1 Score: {svm_f1: .3f}")

#Calculamos y mostramos la matriz de confusion
svm_conf_matrix = confusion_matrix(y_test, svm_y_pred)
plt.figure(figsize=(8, 6))
sns.heatmap(svm_conf_matrix, annot=True, fmt="d", cmap="Blues")
plt.xlabel("Negative Labels")
plt.ylabel("True Labels")
plt.title("SVM Best Confusion Matrix")
plt.show()

"""##√Årboles de decision

Un √°rbol de decisi√≥n es un algoritmo de aprendizaje supervisado no param√©trico, que se utiliza tanto para tareas de clasificaci√≥n como de regresi√≥n. Tiene una estructura de √°rbol jer√°rquica, que consta de un nodo ra√≠z, ramas, nodos internos y nodos hoja.

En funci√≥n de las caracter√≠sticas disponibles, ambos tipos de nodos realizan evaluaciones para formar subconjuntos homog√©neos que se indican mediante nodos hoja o nodos terminales. Los nodos hoja representan todos los resultados posibles dentro del conjunto de datos.

El aprendizaje del √°rbol de decisiones emplea una estrategia de divide y vencer√°s mediante la realizaci√≥n de una b√∫squeda codiciosa para identificar los puntos de divisi√≥n √≥ptimos dentro de un √°rbol. Este proceso de divisi√≥n se repite de forma recursiva de arriba hacia abajo hasta que todos o la mayor√≠a de los registros se hayan clasificado bajo eriquetas de clase espec√≠ficas.

Parametros por default:



1.   criterion='gini'
2.   splitter='best'
3.   max_depth=None
4.   min_samples_split=2
5.   min_samples_leaf=1
6.   min_weight_fraction_leaf=0.0
7.   max_features=None
8.   random_state=None
9.   max_leaf_nodes=None
10.   min_impurity_decrease=0.0
11.   class_weight=None
12.   ccp_alpha=0.0
13.   monotonic_cst=None
"""

# Arbol de decision con par√°metros por defecto
dtc_default = DecisionTreeClassifier()
dtc_default.fit(X_train, y_train)

print(f"Precision en el conjunto de entrenamiento: {dtc_default.score(X_train, y_train):.9f}")
print(f"Precision en el conjunto de prueba: {dtc_default.score(X_test, y_test):.9f}")

# Predicciones
y_pred_dtc_default = dtc_default.predict(X_test)

y_pred_probs = dtc_default.predict_proba(X_test)[:,1]
score = roc_auc_score(y_test, y_pred_probs)
fpr, tpr, thresholds = roc_curve(y_test, y_pred_probs)

print(f"ROC-AUC score: {score}")
plt.figure()
plt.title("DTC Default Curve ROC")
plt.plot(fpr,tpr,color='red', label=f'AUC ROC= {score:.5f})')
plt.plot([0,1],[0,1],linestyle='--',color='gray')
plt.xlabel("False Positive Rate")
plt.ylabel("True Positive Rate")
plt.legend(loc='lower right')
plt.show()

#METRICAS CON LOS DATOS POR DEFAULT

#Calculamos las metricas
accuracy = accuracy_score(y_test, y_pred_dtc_default)
precision = precision_score(y_test, y_pred_dtc_default)
recall = recall_score(y_test, y_pred_dtc_default)
f1 = f1_score(y_test, y_pred_dtc_default)

#Mostramos las metricas
print(f"Accuracy: {accuracy:.3f}")
print(f"Presicion {precision:.3f}")
print(f"recall: {recall:.3f}")
print(f"F1 Score: {f1:.3f}")

#Calculamos y mostramos la matriz de confusion
conf_matrix = confusion_matrix(y_test, y_pred_dtc_default)
plt.figure(figsize=(8, 6))
sns.heatmap(conf_matrix, annot=True, fmt="d", cmap="Blues")
plt.xlabel("Negative Labels")
plt.ylabel("True Labels")
plt.title("DTC Default Confusion Matrix")
plt.show()

from sklearn.tree import DecisionTreeClassifier

#Creamos y configuramos un pipeline con seleccion de caracteristicas, escalado
#y clasificacion

selector = SelectKBest()
scaler = MinMaxScaler()
clf = DecisionTreeClassifier(random_state=42)

dtc_pipeline = Pipeline([('selector', selector),
               ('escalador', scaler),
               ('clasificador', clf)])

#Definimos el diccionario param_grd que contiene las combinaciones de parametros
#que se probaran durante la busqueda de hiperparametros

param_grid_dtc = {
    "selector__k": [2, 3, 4, 5], #Numero de caracteristicas
    "clasificador__criterion": ['gini', 'entropy'], #Criterio de division
    "clasificador__max_depth": [None, 2, 5, 7, 10], #Profundidad macima del arbol
    "clasificador__min_samples_split": [2, 5, 10], #Numero minimo de muestras para dividir un nodo
    "clasificador__min_samples_leaf": [1, 2, 4] #Numero mimimo de muestras por hoja
}

#Busqueda de cuadricula con validacion cruzada
grid_search_dtc = GridSearchCV(dtc_pipeline, param_grid_dtc, cv=5, scoring='accuracy')
grid_search_dtc.fit(X_train, y_train)

#Mejores parametros y score obtenido
print("Mejores parametros para DTC ", grid_search_dtc.best_params_)
print("Mejor accuracy para DTC obtenida en validacion cruzada: ", grid_search_dtc.best_score_)

best_model = grid_search_dtc.best_estimator_
print(f"Precision en el conjunto de entrenamiento: {best_model.score(X_train, y_train):.9f}")
print(f"Precision en el conjunto de prueba: {best_model.score(X_test, y_test):.9f}")

#Curva ROC para SVM
dtc_pred_probs = grid_search_dtc.predict_proba(X_test)[:, 1]
dtc_score = roc_auc_score(y_test, dtc_pred_probs)
dtc_fpr, dtc_tpr, _ = roc_curve(y_test, dtc_pred_probs)

#Grafica de la curva ROC
plt.figure()
print(f"ROC-AUC score: {score}")
plt.title("Curve ROC")
plt.plot(dtc_fpr,dtc_tpr,color='red', label=f'AUC ROC= {score:.5f})')
plt.plot([0,1],[0,1],linestyle='--',color='gray')
plt.xlabel("False Positive Rate")
plt.ylabel("True Positive Rate")
plt.legend(loc='lower right')
plt.show()

#METRICAS

#Generamos las predicciones del modelo DTC
dtc_y_pred = grid_search_dtc.predict(X_test)

#Calculamos las metricas
dtc_accuracy = accuracy_score(y_test, dtc_y_pred)
dtc_precision = precision_score(y_test, dtc_y_pred)
dtc_recall = recall_score(y_test, dtc_y_pred)
dtc_f1 = f1_score(y_test, dtc_y_pred)

print(f"SVM Accuracy: {dtc_accuracy: .3f}")
print(f"SVM Precision: {dtc_precision: .3f}")
print(f"SVM Recall: {dtc_recall: .3f}")
print(f"SVM F1 Score: {dtc_f1: .3f}")

#Calculamos y mostramos la matriz de confusion
dtc_conf_matrix = confusion_matrix(y_test, dtc_y_pred)
plt.figure(figsize=(8, 6))
sns.heatmap(dtc_conf_matrix, annot=True, fmt="d", cmap="Blues")
plt.xlabel("Negative Labels")
plt.ylabel("True Labels")
plt.title("DTC Best Confusion Matrix")
plt.show()

"""##Random Forest

Es un algoritmo de machine learning de uso com√∫n registrado por Leo Breiman y Adele Cutler, que combina la salida de m√∫ltiples √°rboles de decisi√≥n para alcanzar un solo resultado. Su facilidad de uso y flexibilidad han impulsado su adopci√≥n, ya que maneja problemas de clasificaci√≥n y regresi√≥n.

El algoritmo de bosque aleatorio es una extensi√≥n del m√©todo de ensacado, ya que utiliza tanto el ensacado como la aleatoriedad de caracter√≠sticas para crear un bosque no correlacionado de √°rboles de decisi√≥n.

Mientras que los √°rboles de decisi√≥n consideran todas las posibles divisiones de caracter√≠sticas, los bosques aleatorios solo seleccionan un subconjunto de esas caracter√≠sticas.

Parametros por default:



1.   n_estimators=100
2.   criterion='gini'
3.   max_depth=None
4.   min_samples_split=2
5.   min_samples_leaf=1
6.   min_weight_fraction_leaf=0.0
7.   max_features='sqrt'
8.   max_leaf_nodes=None
9.   min_impurity_decrease=0.0
10.   bootstrap=True
11.   oob_score=False
12.   n_jobs=None
13.   random_state=None
14.   verbose=0
15.   warm_start=False
16.   class_weight=None
17.   ccp_alpha=0.0
18.   max_samples=None
19.   monotonic_cst=None
"""

# Random Forest con par√°metros por defecto
rfc_default = RandomForestClassifier()
rfc_default.fit(X_train, y_train)

print(f"Precision en el conjunto de entrenamiento: {rfc_default.score(X_train, y_train):.9f}")
print(f"Precision en el conjunto de prueba: {rfc_default.score(X_test, y_test):.9f}")

# Predicciones
y_pred_rfc_default = rfc_default.predict(X_test)

y_pred_probs = rfc_default.predict_proba(X_test)[:,1]
score = roc_auc_score(y_test, y_pred_probs)
fpr, tpr, thresholds = roc_curve(y_test, y_pred_probs)

print(f"ROC-AUC score: {score}")
plt.figure()
plt.title("RFC Default Curve ROC")
plt.plot(fpr,tpr,color='red', label=f'AUC ROC= {score:.5f})')
plt.plot([0,1],[0,1],linestyle='--',color='gray')
plt.xlabel("False Positive Rate")
plt.ylabel("True Positive Rate")
plt.legend(loc='lower right')
plt.show()

#METRICAS CON LOS DATOS POR DEFAULT

#Calculamos las metricas
accuracy = accuracy_score(y_test, y_pred_rfc_default)
precision = precision_score(y_test, y_pred_rfc_default)
recall = recall_score(y_test, y_pred_rfc_default)
f1 = f1_score(y_test, y_pred_rfc_default)

#Mostramos las metricas
print(f"Accuracy: {accuracy:.3f}")
print(f"Presicion {precision:.3f}")
print(f"recall: {recall:.3f}")
print(f"F1 Score: {f1:.3f}")

#Calculamos y mostramos la matriz de confusion
conf_matrix = confusion_matrix(y_test, y_pred_rfc_default)
plt.figure(figsize=(8, 6))
sns.heatmap(conf_matrix, annot=True, fmt="d", cmap="Blues")
plt.xlabel("Negative Labels")
plt.ylabel("True Labels")
plt.title("RFC Default Confusion Matrix")
plt.show()

from sklearn.ensemble import RandomForestClassifier

#Creamos y configuramos un pipeline con seleccion de caracteristicas, escalado
#y clasificacion

selector = SelectKBest()
scaler = MinMaxScaler()
clf = RandomForestClassifier(random_state=42)

rfc_pipeline = Pipeline([('selector', selector),
               ('escalador', scaler),
               ('clasificador', clf)])

#Definimos el diccionario param_grd que contiene las combinaciones de parametros
#que se probaran durante la busqueda de hiperparametros

param_grid_rfc = {
    "selector__k": [2, 3, 4, 5], #Numero de caracteristicas
    "clasificador__n_estimators": [75], #Numero de arboles en el bosque
    "clasificador__criterion": ['gini', 'entropy'], #Criterio de division
    "clasificador__max_depth": [None, 10, 20, 30, 40, 50], #Profundidad macima del arbol
    "clasificador__min_samples_split": [2, 5, 10], #Numero minimo de muestras para dividir un nodo
    "clasificador__min_samples_leaf": [1, 2, 4] #Numero mimimo de muestras por hoja
}

#Busqueda de cuadricula con validacion cruzada
grid_search_rfc = GridSearchCV(rfc_pipeline, param_grid_rfc, cv=5, scoring='accuracy')
grid_search_rfc.fit(X_train, y_train)

#Mejores parametros y score obtenido
print("Mejores parametros para RFC ", grid_search_rfc.best_params_)
print("Mejor accuracy para RFC obtenida en validacion cruzada: ", grid_search_rfc.best_score_)

best_model = grid_search_rfc.best_estimator_
print(f"Precision en el conjunto de entrenamiento: {best_model.score(X_train, y_train):.9f}")
print(f"Precision en el conjunto de prueba: {best_model.score(X_test, y_test):.9f}")

#Curva ROC para Random Forest
rfc_pred_probs = grid_search_rfc.predict_proba(X_test)[:, 1]
rfc_score = roc_auc_score(y_test, rfc_pred_probs)
rfc_fpr, rfc_tpr, _ = roc_curve(y_test, rfc_pred_probs)

#Grafica de la curva ROC
plt.figure()
plt.title("RFC Best Curve ROC")
plt.plot(rfc_fpr,rfc_tpr,color='red', label=f'AUC ROC= {score:.5f})')
plt.plot([0,1],[0,1],linestyle='--',color='gray')
plt.xlabel("False Positive Rate")
plt.ylabel("True Positive Rate")
plt.legend(loc='lower right')
plt.show()

#METRICAS

#Generamos las predicciones del modelo Random Forest
rfc_y_pred = grid_search_rfc.predict(X_test)

#Calculamos las metricas
rfc_accuracy = accuracy_score(y_test, rfc_y_pred)
rfc_precision = precision_score(y_test, rfc_y_pred)
rfc_recall = recall_score(y_test, rfc_y_pred)
rfc_f1 = f1_score(y_test, rfc_y_pred)

print(f"SVM Accuracy: {dtc_accuracy: .3f}")
print(f"SVM Precision: {dtc_precision: .3f}")
print(f"SVM Recall: {dtc_recall: .3f}")
print(f"SVM F1 Score: {dtc_f1: .3f}")

#Calculamos y mostramos la matriz de confusion
dtc_conf_matrix = confusion_matrix(y_test, rfc_y_pred)
plt.figure(figsize=(8, 6))
sns.heatmap(dtc_conf_matrix, annot=True, fmt="d", cmap="Blues")
plt.xlabel("Negative Labels")
plt.ylabel("True Labels")
plt.title("RFC Best Confusion Matrix")
plt.show()

"""#Tabla de mejores modelos dada la cantidad de true positives obtenidos"""

#Definimos los modelos
models ={
    "Logistic Regression Default": LogisticRegression(max_iter=1000),
    "Logistic Regression Best": LogisticRegression(C=0.1, penalty='l1', solver='saga', max_iter=1000),
    "SVM Default": SVC(probability=True),
    "SVM Best": SVC(C=10, gamma='scale', kernel='rbf', probability=True),
    "Decision Tree Default": DecisionTreeClassifier(),
    "Decision Tree Best": DecisionTreeClassifier(criterion='entropy', max_depth=10, min_samples_leaf=2, min_samples_split=10),
    "Random Forest Default": RandomForestClassifier(),
    "Random Forest Best": RandomForestClassifier(criterion='entropy', max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=75)
}

#Entrenamos y evaluamos los modelos con parametros
metrics = []
for name, model in models.items():
  model.fit(X_train, y_train)
  y_pred = model.predict(X_test)
  y_pred_probs = model.predict_proba(X_test)[:,1]

  accuracy = accuracy_score(y_test, y_pred)
  precision = precision_score(y_test, y_pred)
  recall = recall_score(y_test, y_pred)
  f1 = f1_score(y_test, y_pred)
  roc_auc = roc_auc_score(y_test, y_pred_probs)

  conf_matrix = confusion_matrix(y_test, y_pred)
  tp = conf_matrix[1, 1]

  train_accuracy = model.score(X_train, y_train)
  test_accuracy = model.score(X_test, y_test)

  metrics.append({
        "Model": name,
        "Accuracy": accuracy,
        "Precision": precision,
        "Recall": recall,
        "F1 Score": f1,
        "True Positives": tp,
        "ROC Curve" : roc_auc,
        "Train Accuracy": train_accuracy,
        "Test Accuracy": test_accuracy
    })

#Convertimos las metricas en un DataFrame y ordenamos por True Positive
metrics_df = pd.DataFrame(metrics)
metrics_df = metrics_df.sort_values(by="Precision", ascending=False)
print(metrics_df)

#Seleccionamos el mejor modelo
best_model_name = metrics_df.iloc[0]["Model"]
best_model = models[best_model_name]
print(f"Mejor modelo: {best_model_name}")

"""#Hacemos la prediccion

Tomamos en cuanta estos parametros para predecir un platano bueno
![image.png](data:image/png;base64,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)

Y estos para uno malo

![image.png](data:image/png;base64,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)
"""

X_new = pd.DataFrame([[-0.5928164, -0.1690181, 1.3613776, -2.6591895, -1.0305489,
                       1.2555294, 1.1610047]],
                     columns=["Size", "Weight", "Sweetness", "Softness",
                              "HarvestTime", "Ripeness", "Acidity"])
y_new_pred = best_model.predict(X_new)
quality = "Buena" if y_new_pred[0] == 1 else "Mala"
print(f"La calidad del platano segun el modelo es: {quality}")

X_new = pd.DataFrame([[-1.2686903, -1.3534002, 0.043051597, -2.5606737, -3.6765728,
                       0.31831023, -0.25261405]],
                     columns=["Size", "Weight", "Sweetness", "Softness",
                              "HarvestTime", "Ripeness", "Acidity"])
y_new_pred = best_model.predict(X_new)
quality = "Buena" if y_new_pred[0] == 1 else "Mala"
print(f"La calidad del platano segun el modelo es: {quality}")

"""Ahora haremos predicciones nuevas"""

X_new = pd.DataFrame([[-2.9812314, 0.2348123, 4.1228103, -1.2449129, 3.1245812,
                       0.2145145, 2.3148141]],
                     columns=["Size", "Weight", "Sweetness", "Softness",
                              "HarvestTime", "Ripeness", "Acidity"])
y_new_pred = best_model.predict(X_new)
quality = "Buena" if y_new_pred[0] == 1 else "Mala"
print(f"La calidad del platano segun el modelo es: {quality}")

X_new = pd.DataFrame([[-2.4564312, 0.2131494, 3.1214912, -1.1394012, -5.1284024,
                       0.4212892, -3.5102942]],
                     columns=["Size", "Weight", "Sweetness", "Softness",
                              "HarvestTime", "Ripeness", "Acidity"])
y_new_pred = best_model.predict(X_new)
quality = "Buena" if y_new_pred[0] == 1 else "Mala"
print(f"La calidad del platano segun el modelo es: {quality}")